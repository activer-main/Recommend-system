{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7442cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b837db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "activity_df = pd.read_csv('data/preprocess/activity.csv', index_col='id')\n",
    "\n",
    "activity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea4836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab85ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_content = activity_df['content']\n",
    "# 將沒有 content 填成 title\n",
    "activity_df['content'].fillna(activity_df['title'], inplace=True)\n",
    "# activity_df.index\n",
    "activity_df[activity_df['content'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81503a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac88663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckip_transformers import __version__\n",
    "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger, CkipNerChunker\n",
    "\n",
    "\n",
    "# Show version\n",
    "print(__version__)\n",
    "\n",
    "# Initialize drivers\n",
    "print(\"Initializing drivers ... WS\")\n",
    "ws_driver = CkipWordSegmenter(model=\"albert-base\")\n",
    "print(\"Initializing drivers ... POS\")\n",
    "pos_driver = CkipPosTagger(model=\"albert-base\")\n",
    "print(\"Initializing drivers ... NER\")\n",
    "ner_driver = CkipNerChunker(model=\"albert-base\")\n",
    "print(\"Initializing drivers ... all done\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90e58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean function\n",
    "def clean(sentence_ws, sentence_pos):\n",
    "  short_with_pos = []\n",
    "  short_sentence = []\n",
    "  stop_pos = set(['Nep', 'Nh', 'Nb']) # 這 3 種詞性不保留 指代定詞 代名詞 專有名詞\n",
    "  for word_ws, word_pos in zip(sentence_ws, sentence_pos):\n",
    "    # 只留名詞和動詞\n",
    "    is_N_or_V = word_pos.startswith(\"V\") or word_pos.startswith(\"N\")\n",
    "    # 去掉名詞裡的某些詞性\n",
    "    is_not_stop_pos = word_pos not in stop_pos\n",
    "    # 只剩一個字的詞也不留\n",
    "    is_not_one_charactor = not (len(word_ws) == 1)\n",
    "    \n",
    "    # 組成串列\n",
    "    if is_N_or_V and is_not_stop_pos and is_not_one_charactor:\n",
    "      short_with_pos.append(f\"{word_ws}({word_pos})\")\n",
    "      short_sentence.append(f\"{word_ws}\")\n",
    "  return (\" \".join(short_sentence), \" \".join(short_with_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90174173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = ws_driver(activity_content)\n",
    "pos = pos_driver(ws)\n",
    "ner = ner_driver(activity_content)\n",
    "print()\n",
    "print('=====')\n",
    "\n",
    "index = 0\n",
    "activity_content_text = []\n",
    "\n",
    "# The zip() function in Python is used to combine elements from two or more iterable objects into tuples.\n",
    "for sentence, sentence_ws, sentence_pos, sentence_ner in zip(activity_content, ws, pos, ner):\n",
    "\n",
    "#     print(\"原文：\")\n",
    "#     print(sentence)\n",
    "\n",
    "    (short, res) = clean(sentence_ws, sentence_pos)\n",
    "    activity_content_text.append(short)\n",
    "\n",
    "#     print(\"斷詞後：\")\n",
    "#     print(short)\n",
    "#     print(\"斷詞後+詞性標注：\")\n",
    "#     print(res)\n",
    "#     print('=====')\n",
    "#     print(sentence)\n",
    "#     print(sentence_ws)\n",
    "#     print(sentence_ner)\n",
    "\n",
    "activity_content_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b781e458",
   "metadata": {},
   "source": [
    "## 設立使用者資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity_content = ['']\n",
    "user_history = [5]\n",
    "for index in user_history:\n",
    "    user_activity_content[0] += activity_df.iloc[index]['content']\n",
    "\n",
    "user_activity_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c46742",
   "metadata": {},
   "source": [
    "## 做斷詞分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67faf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = ws_driver(user_activity_content)\n",
    "pos = pos_driver(ws)\n",
    "ner = ner_driver(user_activity_content)\n",
    "print()\n",
    "print('=====')\n",
    "\n",
    "user_content_text = []\n",
    "\n",
    "# The zip() function in Python is used to combine elements from two or more iterable objects into tuples.\n",
    "for sentence, sentence_ws, sentence_pos, sentence_ner in zip(user_activity_content, ws, pos, ner):\n",
    "    (short, res) = clean(sentence_ws, sentence_pos)\n",
    "    user_content_text.append(short)\n",
    "\n",
    "user_content_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0021c193",
   "metadata": {},
   "source": [
    "## 算出使用者和活動的 TF-IDF 特徵矩陣，並算出相似值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 目的是學習每個單詞在所有文本中的重要性，轉換的目的是將每個文本轉換成一個數值向量\n",
    "activity_vec = vectorizer.fit_transform(activity_content_text)\n",
    "\n",
    "# 已經有一個訓練好的向量化模型，並且想要將新的文本資料轉換成與這個模型相同的向量形式\n",
    "user_vec = vectorizer.transform(user_content_text)\n",
    "\n",
    "# 計算使用者向量和語料庫中所有活動向量之間的餘弦相似度\n",
    "user_activity_matrix = cosine_similarity(user_vec, activity_vec)\n",
    "\n",
    "# 透過增加字元的方式調整單詞權重\n",
    "print(activity_vec.toarray()[0][0:20])\n",
    "\n",
    "user_activity_matrix = pd.DataFrame(user_activity_matrix, index=user_pd.index, columns=activity_df.index)\n",
    "\n",
    "user_activity_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
